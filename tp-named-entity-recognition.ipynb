{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/papamagattediop/travaux_nlp/blob/main/tp-named-entity-recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fc6a802-18ed-4e59-b966-e7ac1b78ca57",
      "metadata": {
        "id": "6fc6a802-18ed-4e59-b966-e7ac1b78ca57"
      },
      "source": [
        "**Summary**\n",
        "\n",
        "L'objectif de ce TP est de découvrir et de mettre en pratique la Reconnaissance d'Entités Nommées (NER) en utilisant :\n",
        "\n",
        "- Le dataset CoNLL-2003, un benchmark standard pour la NER.\n",
        "    - Contient des phrases en anglais avec des entités annotées (Personnes, Organisations, Lieux, Dates, etc.)\n",
        "    - Format : chaque mot est associé à une étiquette (O, B-PER, I-LOC, etc.)\n",
        "- La bibliothèque spaCy, un outil puissant pour le traitement du langage naturel (NLP).\n",
        "\n",
        "La NER est une tâche de NLP qui consiste à identifier et classer des entités nommées dans un texte (par exemple, noms de personnes, organisations, lieux, dates).\n",
        "\n",
        "spaCy est une bibliothèque open-source pour le traitement du langage naturel (NLP) et inclut des modèles pré-entraînés pour la NER. Elle peut être utilisée pour construire des systèmes d’extraction d’information, de compréhension du langage naturel ou de prétraitement de texte en vue d’un apprentissage approfondi. Cependant, spaCy ne prend pas en charge directement le format CoNLL-2003, donc nous devrons d'abord convertir les données dans un format compatible avec spaCy. Pour plus de détails, vous pouvez consulter cette [vidéo](https://youtu.be/sqDHBH9IjRU).\n",
        "Le modèle NER de SpaCy est basé sur les CNN (Convolutional Neural Networks).\n",
        "\n",
        "Vous pouvez explorer d'autres datasets NER comme OntoNotes ou WikiNER.\n",
        "\n",
        "\n",
        "Il existe des outils d’annotation pour NER comme [Prodigy](https://prodi.gy/) ou autre, mentionné [ici](https://medium.com/dataturks/document-pdf-annotation-tool-f13d94a4b9c). Ces outils permettent de taggers les entités nommées dans chaque séquence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9d98a663-e2eb-441c-9cd8-003c6c403214",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-18T09:19:49.097961Z",
          "iopub.status.busy": "2025-03-18T09:19:49.097120Z",
          "iopub.status.idle": "2025-03-18T09:21:55.092972Z",
          "shell.execute_reply": "2025-03-18T09:21:55.092443Z",
          "shell.execute_reply.started": "2025-03-18T09:19:49.097923Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "9d98a663-e2eb-441c-9cd8-003c6c403214",
        "outputId": "b66e308b-704a-418d-f651-e9fbde88ea1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (1.3.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 77.8 MB/s eta 0:00:00\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 400.7/400.7 MB 4.1 MB/s eta 0:00:00\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "pip install spacy datasets\n",
        "\n",
        "# Download model\n",
        "python -m spacy download en_core_web_sm\n",
        "python -m spacy download en_core_web_lg\n",
        "\n",
        "# List of available models: https://spacy.io/models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "798f9953-9014-4ca0-9a45-1e8910d3821e",
      "metadata": {
        "id": "798f9953-9014-4ca0-9a45-1e8910d3821e"
      },
      "source": [
        "# Import librairies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install loguru"
      ],
      "metadata": {
        "id": "FGHic0YY1rw7",
        "outputId": "e031b3cc-b3b1-45dc-86b7-1f110e823da8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FGHic0YY1rw7",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru\n",
            "Successfully installed loguru-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "aea6a14d-2545-49a2-968c-f8dd8cd4cfd6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:16:18.126960Z",
          "iopub.status.busy": "2025-03-18T09:16:18.126814Z",
          "iopub.status.idle": "2025-03-18T09:16:18.707863Z",
          "shell.execute_reply": "2025-03-18T09:16:18.707605Z",
          "shell.execute_reply.started": "2025-03-18T09:16:18.126951Z"
        },
        "id": "aea6a14d-2545-49a2-968c-f8dd8cd4cfd6"
      },
      "outputs": [],
      "source": [
        "from os import environ\n",
        "from tqdm import tqdm\n",
        "\n",
        "from loguru import logger\n",
        "from pathlib import Path\n",
        "from spacy.tokens import DocBin"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62a8dd10-eb73-468a-89b0-9f0497504b6e",
      "metadata": {
        "id": "62a8dd10-eb73-468a-89b0-9f0497504b6e"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1cbb10c8-f442-4766-a08f-79b0a730ec41",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:16:29.490119Z",
          "iopub.status.busy": "2025-03-18T09:16:29.489224Z",
          "iopub.status.idle": "2025-03-18T09:16:29.500754Z",
          "shell.execute_reply": "2025-03-18T09:16:29.500258Z",
          "shell.execute_reply.started": "2025-03-18T09:16:29.490082Z"
        },
        "id": "1cbb10c8-f442-4766-a08f-79b0a730ec41",
        "outputId": "c588bd06-8cb5-4a1a-acf8-a3f502ee3a35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2026-02-05 17:26:52.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1m\n",
            "Root directory: / \n",
            "Data directory: /data \n",
            "Config directory: /config \n",
            "Output directory: /ner_output\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "ROOT_DIR = Path.cwd().parent  # project folder\n",
        "DATA_DIR = Path(ROOT_DIR, \"data\")  # data\n",
        "CONFIG_DIR = Path(ROOT_DIR, \"config\")  # config, bins\n",
        "OUTPUT_DIR  = Path(ROOT_DIR, \"ner_output\")  # models\n",
        "\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "CONFIG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Add paths in env\n",
        "environ[\"SPACY_BINS_DIR\"] = str(CONFIG_DIR)\n",
        "environ[\"SPACY_DATA_DIR\"] = str(DATA_DIR)\n",
        "environ[\"SPACY_OUTPUT_DIR\"] = str(OUTPUT_DIR)\n",
        "\n",
        "logger.info(f\"\\nRoot directory: {ROOT_DIR} \\nData directory: {DATA_DIR} \\nConfig directory: {CONFIG_DIR} \\nOutput directory: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5760b482-d11c-4b58-a480-48d4743be03f",
      "metadata": {
        "id": "5760b482-d11c-4b58-a480-48d4743be03f"
      },
      "source": [
        "# Use spaCy to make a NER example"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10b9fcfc-32c2-4675-8e91-e823ea701dc8",
      "metadata": {
        "id": "10b9fcfc-32c2-4675-8e91-e823ea701dc8"
      },
      "source": [
        "### Test pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca856237-4df5-4b52-8e43-0dfb32dfd0bc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:16:32.085981Z",
          "iopub.status.busy": "2025-03-18T09:16:32.085681Z",
          "iopub.status.idle": "2025-03-18T09:16:32.409394Z",
          "shell.execute_reply": "2025-03-18T09:16:32.409151Z",
          "shell.execute_reply.started": "2025-03-18T09:16:32.085960Z"
        },
        "id": "ca856237-4df5-4b52-8e43-0dfb32dfd0bc",
        "outputId": "c3e866c4-dd40-4934-d8f4-f3379ee868e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apple -> ORG\n",
            "U.K. -> GPE\n",
            "$1 billion -> MONEY\n",
            "2023 -> DATE\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Text example\n",
        "text = \"Apple is looking at buying U.K. startup for $1 billion in 2023.\"\n",
        "\n",
        "# Text preprocessing\n",
        "doc = nlp(text)\n",
        "\n",
        "# Display entity\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text} -> {ent.label_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "144a8b96-1843-494a-bacf-3a085f899718",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:16:32.602411Z",
          "iopub.status.busy": "2025-03-18T09:16:32.602115Z",
          "iopub.status.idle": "2025-03-18T09:18:38.378950Z",
          "shell.execute_reply": "2025-03-18T09:18:38.377799Z",
          "shell.execute_reply.started": "2025-03-18T09:16:32.602389Z"
        },
        "scrolled": true,
        "id": "144a8b96-1843-494a-bacf-3a085f899718",
        "outputId": "7670d847-363c-46cd-fba5-4721f27516b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/spacy/util.py:1835: UserWarning: [W124] 0.0.0.0:5000 is already in use, using the nearest available port 5001 as an alternative.\n",
            "  warnings.warn(Warnings.W124.format(host=host, port=start, serve_port=port))\n",
            "/opt/anaconda3/lib/python3.12/site-packages/spacy/displacy/__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
            "  warnings.warn(Warnings.W011)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is looking at buying \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    U.K.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " startup for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $1 billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2023\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".</div>\n",
              "</figure>\n",
              "</body>\n",
              "</html></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'ent' visualizer\n",
            "Serving on http://0.0.0.0:5001 ...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2025 09:18:25] \"GET / HTTP/1.1\" 200 1682\n",
            "127.0.0.1 - - [18/Mar/2025 09:18:25] \"GET /favicon.ico HTTP/1.1\" 200 1682\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shutting down server on port 5001.\n"
          ]
        }
      ],
      "source": [
        "spacy.displacy.serve(doc, style=\"ent\", auto_select_port=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fd14b62-8707-4f74-8767-b7d624ca13e3",
      "metadata": {
        "id": "4fd14b62-8707-4f74-8767-b7d624ca13e3"
      },
      "source": [
        "### SpaCy QickStart\n",
        "\n",
        "https://spacy.io/usage/training#quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7501e510-2c8b-43b0-986d-f9150579cf31",
      "metadata": {
        "id": "7501e510-2c8b-43b0-986d-f9150579cf31"
      },
      "source": [
        "# Train a custom NER"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b92f8e5-ec2e-46dc-845c-0d034d9872fa",
      "metadata": {
        "id": "9b92f8e5-ec2e-46dc-845c-0d034d9872fa"
      },
      "source": [
        "## Load data\n",
        "\n",
        "Le jeu de données CoNLL-2003, très connu pour les tâches de Reconnaissance d'Entités Nommées (NER) comme PERSON, LOCATION, ORGANIZATION, etc;\n",
        "\n",
        "Le dataset CoNLL-2003 est structuré comme suit :\n",
        "\n",
        "- Chaque phrase est représentée par une séquence de tokens.\n",
        "- Chaque token est associé à une étiquette NER au format IOB (Inside, Outside, Beginning).\n",
        "    - `B-PER` : Début d'une entité de type \"Personne\".\n",
        "    - `I-PER` : Suite d'une entité de type \"Personne\".\n",
        "    - `B-ORG` : Début d'une entité de type \"Organisation\".\n",
        "    - `I-ORG` : Suite d'une entité de type \"Organisation\".\n",
        "    - `B-LOC` : Début d'une entité de type \"Lieu\".\n",
        "    - `I-LOC` : Suite d'une entité de type \"Lieu\".\n",
        "    - `B-MISC` : Début d'une entité de type \"Divers\".\n",
        "    - `I-MISC` : Suite d'une entité de type \"Divers\".\n",
        "    - `O` : Token ne faisant pas partie d'une entité."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ddb2fba-3cab-42eb-961d-0e3287534a75",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:18:38.392994Z",
          "iopub.status.busy": "2025-03-18T09:18:38.392847Z",
          "iopub.status.idle": "2025-03-18T09:18:42.264824Z",
          "shell.execute_reply": "2025-03-18T09:18:42.264545Z",
          "shell.execute_reply.started": "2025-03-18T09:18:38.392980Z"
        },
        "id": "3ddb2fba-3cab-42eb-961d-0e3287534a75",
        "outputId": "c8cc1fea-be4e-4d70-a041-04494753fa35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-03-18 09:18:42.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1m\n",
            " {'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset_conll = load_dataset(\"conll2003\")\n",
        "logger.info(f\"\\n {dataset_conll['train'][0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b27fba-63b0-4cc0-b95e-fdeba9aee81d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:18:42.266935Z",
          "iopub.status.busy": "2025-03-18T09:18:42.266284Z",
          "iopub.status.idle": "2025-03-18T09:18:42.269958Z",
          "shell.execute_reply": "2025-03-18T09:18:42.269693Z",
          "shell.execute_reply.started": "2025-03-18T09:18:42.266902Z"
        },
        "id": "83b27fba-63b0-4cc0-b95e-fdeba9aee81d",
        "outputId": "98c5cca7-c68b-4cff-fa64-c8d699aee660"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-03-18 09:18:42.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mNER labels: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "label_list = dataset_conll[\"train\"].features[\"ner_tags\"].feature.names\n",
        "logger.info(f\"NER labels: {label_list}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb499e7f-f692-487a-8948-53d39c0f3321",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:18:42.270491Z",
          "iopub.status.busy": "2025-03-18T09:18:42.270416Z",
          "iopub.status.idle": "2025-03-18T09:18:42.273661Z",
          "shell.execute_reply": "2025-03-18T09:18:42.273371Z",
          "shell.execute_reply.started": "2025-03-18T09:18:42.270482Z"
        },
        "id": "cb499e7f-f692-487a-8948-53d39c0f3321",
        "outputId": "e77c7f13-0a38-43c0-d824-94878093f7ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example\n",
        "dataset_conll[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2b381e4-8ed2-4439-9abd-58ad60465481",
      "metadata": {
        "id": "c2b381e4-8ed2-4439-9abd-58ad60465481"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1197fa4b-efdb-4c39-9a21-e5bc2503b04d",
      "metadata": {
        "id": "1197fa4b-efdb-4c39-9a21-e5bc2503b04d"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "- Conversion des données en objets Doc et DocBin, le format interne de spaCy.\n",
        "- Reconstruction des entités à partir des tags IOB (Begin, Inside, Outside)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e0b1de9-39f7-4e62-a528-5c42a5149f5b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:19:11.281693Z",
          "iopub.status.busy": "2025-03-18T09:19:11.280641Z",
          "iopub.status.idle": "2025-03-18T09:19:11.288079Z",
          "shell.execute_reply": "2025-03-18T09:19:11.287562Z",
          "shell.execute_reply.started": "2025-03-18T09:19:11.281645Z"
        },
        "id": "2e0b1de9-39f7-4e62-a528-5c42a5149f5b"
      },
      "outputs": [],
      "source": [
        "def create_spacy_docs(dataset_split, label_names):\n",
        "    \"\"\"Convert data to SpaCy format.\"\"\"\n",
        "    db = DocBin()  # doc binary\n",
        "    for example in tqdm(dataset_split, desc=\"Doc binary transformation ...\"):\n",
        "        words = example['tokens']\n",
        "        labels = example['ner_tags']\n",
        "        doc = nlp.make_doc(\" \".join(words))\n",
        "        ents = []\n",
        "        start = 0\n",
        "        for word, label_idx in zip(words, labels):\n",
        "            label = label_names[label_idx]\n",
        "            word_start = doc.text.find(word, start)\n",
        "            word_end = word_start + len(word)\n",
        "            if label != \"O\":\n",
        "                if label.startswith(\"B-\") or label.startswith(\"I-\"):\n",
        "                    ents.append(doc.char_span(word_start, word_end, label=label[2:]))\n",
        "            start = word_end\n",
        "        ents = [e for e in ents if e is not None]\n",
        "        doc.ents = ents\n",
        "        db.add(doc)\n",
        "    return db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3a9883a-268f-49ad-93d0-a65f4c603894",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:19:12.180559Z",
          "iopub.status.busy": "2025-03-18T09:19:12.180281Z",
          "iopub.status.idle": "2025-03-18T09:19:16.185988Z",
          "shell.execute_reply": "2025-03-18T09:19:16.185717Z",
          "shell.execute_reply.started": "2025-03-18T09:19:12.180541Z"
        },
        "id": "a3a9883a-268f-49ad-93d0-a65f4c603894",
        "outputId": "2be6539b-1e42-45dc-de12-4501c0224986"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Doc binary transformation ...: 100%|██████████████████████████████| 14041/14041 [00:02<00:00, 5525.62it/s]\n",
            "Doc binary transformation ...: 100%|████████████████████████████████| 3250/3250 [00:00<00:00, 5328.04it/s]\n",
            "Doc binary transformation ...: 100%|████████████████████████████████| 3453/3453 [00:00<00:00, 6203.51it/s]\n"
          ]
        }
      ],
      "source": [
        "# Create files\n",
        "train_db = create_spacy_docs(dataset_conll[\"train\"], label_names=label_list)\n",
        "valid_db = create_spacy_docs(dataset_conll[\"validation\"], label_names=label_list)\n",
        "test_db = create_spacy_docs(dataset_conll[\"test\"], label_names=label_list)\n",
        "\n",
        "\n",
        "train_db.to_disk(Path(DATA_DIR, \"conll_train.spacy\"))\n",
        "valid_db.to_disk(Path(DATA_DIR, \"conll_valid.spacy\"))\n",
        "test_db.to_disk(Path(DATA_DIR, \"conll_test.spacy\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da5a1886-4c4b-4a62-a3e4-2a9cbe79add1",
      "metadata": {
        "id": "da5a1886-4c4b-4a62-a3e4-2a9cbe79add1"
      },
      "source": [
        "spaCy utilise un fichier de configuration pour définir les paramètres d'entraînement. Vous pouvez générer un fichier de configuration de base avec la commande suivante :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d37f4f6-fc3c-4edb-b4b2-d5d877ab6dbc",
      "metadata": {
        "id": "4d37f4f6-fc3c-4edb-b4b2-d5d877ab6dbc"
      },
      "source": [
        "### SpaCy config file\n",
        "<img src=\"attachment:afb1d94c-f254-4a3f-90c0-70d5e6010102.png\" alt=\"spaCy\" style=\"width: 400px;\"/>\n",
        "\n",
        "le fichier de configuration (`config.cfg`) est un élément indispensable qui définit tous les **composants**, **hyperparamètres** et **pipelines** nécessaires à l’entraînement ou à l’utilisation d’un modèle NLP.\n",
        "\n",
        "**À quoi sert ce fichier ?**\n",
        "- Définir les composants du pipeline (tokenizer, tagger, parser, NER, etc.)\n",
        "- Spécifier les données d'entraînement et de validation\n",
        "- Définir les modèles de embeddings (par exemple, tok2vec)\n",
        "- Choisir les optimiseurs, stratégies d’apprentissage, batch sizes, etc.\n",
        "- Rendre le processus reproductible."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8533303b-b09c-4a93-b8f8-f88a3b3394c6",
      "metadata": {
        "id": "8533303b-b09c-4a93-b8f8-f88a3b3394c6"
      },
      "source": [
        "#### spacy init config\n",
        "\n",
        "La commande spacy init config est utilisée pour générer un fichier de configuration de base pour un projet spaCy. Ce fichier de configuration définit les paramètres d'entraînement, les composants du pipeline, les hyperparamètres, etc.\n",
        "\n",
        "`python -m spacy init config config.cfg --lang en --pipeline ner --optimize efficiency`\n",
        "\n",
        "Options principales :\n",
        "- `lang` : spécifie la langue du modèle (par exemple, `en` pour l'anglais).\n",
        "- `pipeline` : définit les composants du pipeline (par exemple, `ner` pour la reconnaissance d'entités nommées).\n",
        "- `optimize` : spécifie l'optimisation pour `efficiency` (efficacité) ou `accuracy` (précision)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfa2d15e-822c-4d9c-af24-aa1dec2989c0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:24:20.312024Z",
          "iopub.status.busy": "2025-03-18T09:24:20.311726Z",
          "iopub.status.idle": "2025-03-18T09:24:21.598742Z",
          "shell.execute_reply": "2025-03-18T09:24:21.598427Z",
          "shell.execute_reply.started": "2025-03-18T09:24:20.311998Z"
        },
        "id": "dfa2d15e-822c-4d9c-af24-aa1dec2989c0",
        "outputId": "188cb222-525c-4237-c582-a8a69f6a80b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
            "- Language: en\n",
            "- Pipeline: ner\n",
            "- Optimize for: efficiency\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "/Users/mouslydiaw/Documents/ml-courses/nlp/config/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# Generate config file got spaCy\n",
        "python -m spacy init config ${SPACY_BINS_DIR}/config.cfg --lang en --pipeline ner --optimize efficiency --force"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe1968c-5911-4843-a07d-f1bc05b0745f",
      "metadata": {
        "id": "afe1968c-5911-4843-a07d-f1bc05b0745f"
      },
      "source": [
        "#### spacy init fill-config\n",
        "\n",
        "La commande spacy init fill-config est utilisée pour compléter un fichier de configuration existant avec des valeurs par défaut pour les paramètres manquants. Elle est utile lorsque vous avez un fichier de configuration partiel: `base_config`. Ce dernier vous pouvez le télécharger [ici](https://spacy.io/usage/training#quickstart).\n",
        "\n",
        "Un fichier, nommé `acc_config.cfg`, est généré en ajoutant les valeurs par défaut aux paramètres manquants dans `base_config.cfg`. Le nom du fichier peut être personnalisé selon vos préférences. Par exemple, j’ai ajouté le préfixe `acc_` (puisque le fichier `base_config.cfg` a été téléchargé avec l’option `accuracy`) afin de le distinguer de celui généré précédemment avec l’option `efficiency`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef55b196-2bee-46d7-9160-d4fa0156865f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:28:57.187117Z",
          "iopub.status.busy": "2025-03-18T09:28:57.186166Z",
          "iopub.status.idle": "2025-03-18T09:28:58.984455Z",
          "shell.execute_reply": "2025-03-18T09:28:58.984109Z",
          "shell.execute_reply.started": "2025-03-18T09:28:57.187058Z"
        },
        "id": "ef55b196-2bee-46d7-9160-d4fa0156865f",
        "outputId": "15ba0c9b-9c55-4d12-977b-1456424a77bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "/Users/mouslydiaw/Documents/ml-courses/nlp/config/acc_config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train acc_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "python -m spacy init fill-config ${SPACY_BINS_DIR}/acc_base_config.cfg ${SPACY_BINS_DIR}/acc_config.cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "263fbadf-71eb-4b85-b420-ae59dcf613b1",
      "metadata": {
        "id": "263fbadf-71eb-4b85-b420-ae59dcf613b1"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a7f192c-45af-4620-8eff-1c94bc97d635",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:30:00.454394Z",
          "iopub.status.busy": "2025-03-18T09:30:00.454064Z",
          "iopub.status.idle": "2025-03-18T09:30:08.903862Z",
          "shell.execute_reply": "2025-03-18T09:30:08.903552Z",
          "shell.execute_reply.started": "2025-03-18T09:30:00.454372Z"
        },
        "id": "8a7f192c-45af-4620-8eff-1c94bc97d635",
        "outputId": "00662fd8-efe2-433b-ad2b-4402d7ed7c2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start time: 2025-03-18 09:30:00\n",
            "\n",
            "Config file path: /Users/mouslydiaw/Documents/ml-courses/nlp/config \n",
            "Data directory: /Users/mouslydiaw/Documents/ml-courses/nlp/data**************************************** Starting debug config...\n",
            "\n",
            "\u001b[1m\n",
            "============================ Data file validation ============================\u001b[0m\n",
            "\u001b[38;5;2m✔ Pipeline can be initialized with data\u001b[0m\n",
            "\u001b[38;5;2m✔ Corpus is loadable\u001b[0m\n",
            "\u001b[1m\n",
            "=============================== Training stats ===============================\u001b[0m\n",
            "Language: en\n",
            "Training pipeline: tok2vec, ner\n",
            "14041 training docs\n",
            "3250 evaluation docs\n",
            "\u001b[38;5;3m⚠ 129 training examples also in evaluation data\u001b[0m\n",
            "\u001b[1m\n",
            "============================== Vocab & Vectors ==============================\u001b[0m\n",
            "\u001b[38;5;4mℹ 216122 total word(s) in the data (22303 unique)\u001b[0m\n",
            "\u001b[38;5;4mℹ 342918 vectors (684830 unique keys, 300 dimensions)\u001b[0m\n",
            "\u001b[38;5;3m⚠ 6387 words in training data without vectors (3%)\u001b[0m\n",
            "\u001b[1m\n",
            "========================== Named Entity Recognition ==========================\u001b[0m\n",
            "\u001b[38;5;4mℹ 4 label(s)\u001b[0m\n",
            "0 missing value(s) (tokens with '-' label)\n",
            "\u001b[38;5;2m✔ Good amount of examples for all labels\u001b[0m\n",
            "\u001b[38;5;2m✔ Examples without occurrences available for all labels\u001b[0m\n",
            "\u001b[38;5;2m✔ No entities consisting of or starting/ending with whitespace\u001b[0m\n",
            "\u001b[38;5;2m✔ No entities crossing sentence boundaries\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Summary ==================================\u001b[0m\n",
            "\u001b[38;5;2m✔ 6 checks passed\u001b[0m\n",
            "\u001b[38;5;3m⚠ 2 warnings\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "START=$(date '+%Y-%m-%d %H:%M:%S')\n",
        "echo \"Start time: $START\"\n",
        "printf \"\\nConfig file path: $SPACY_BINS_DIR \\nData directory: ${SPACY_DATA_DIR}\"\n",
        "\n",
        "# scan/debug data: vérifier la qualité, la structure et la compatibilité de vos données d'entraînement et de validation\n",
        "printf \"**************************************** Starting debug config...\\n\\n\"\n",
        "python -m spacy debug data $SPACY_BINS_DIR/acc_config.cfg --paths.train $SPACY_DATA_DIR/conll_train.spacy --paths.dev $SPACY_DATA_DIR/conll_valid.spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94d0f5e4-40f1-4ae2-a0c6-59392be38c00",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T09:30:34.582032Z",
          "iopub.status.busy": "2025-03-18T09:30:34.581640Z",
          "iopub.status.idle": "2025-03-18T10:00:10.109263Z",
          "shell.execute_reply": "2025-03-18T10:00:10.107818Z",
          "shell.execute_reply.started": "2025-03-18T09:30:34.582010Z"
        },
        "id": "94d0f5e4-40f1-4ae2-a0c6-59392be38c00",
        "outputId": "3f262693-51fc-4f7c-aee4-e22dfa73cd0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start time: 2025-03-18 09:30:34\n",
            "\n",
            "Config file path: /Users/mouslydiaw/Documents/ml-courses/nlp/config \n",
            "Data directory: /Users/mouslydiaw/Documents/ml-courses/nlp/data \n",
            "Output directory: /Users/mouslydiaw/Documents/ml-courses/nlp/ner_output\n",
            "\n",
            "\n",
            "\n",
            "**************************************** Starting training model...\n",
            "\n",
            "\u001b[38;5;4mℹ Saving to output directory:\n",
            "/Users/mouslydiaw/Documents/ml-courses/nlp/ner_output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     46.28    0.00    0.00    0.00    0.00\n",
            "  0     200         15.27   2230.25   78.06   79.41   76.75    0.78\n",
            "  0     400         39.38   1447.32   85.55   86.39   84.73    0.86\n",
            "  0     600         27.91   1339.62   88.08   88.18   87.99    0.88\n",
            "  0     800         34.16   1422.30   88.32   88.92   87.73    0.88\n",
            "  0    1000         41.58   1581.34   89.53   89.62   89.45    0.90\n",
            "  1    1200         51.19   1513.73   90.91   91.03   90.79    0.91\n",
            "  1    1400         59.42   1199.19   91.03   91.03   91.03    0.91\n",
            "  1    1600        120.14   1524.16   92.06   92.28   91.84    0.92\n",
            "  2    1800         85.39   1422.61   91.67   92.29   91.05    0.92\n",
            "  2    2000         95.80   1288.22   91.83   92.32   91.35    0.92\n",
            "  3    2200        137.29   1203.77   92.00   91.98   92.03    0.92\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "START=$(date '+%Y-%m-%d %H:%M:%S')\n",
        "echo \"Start time: $START\"\n",
        "\n",
        "printf \"\\nConfig file path: $SPACY_BINS_DIR \\nData directory: ${SPACY_DATA_DIR} \\nOutput directory: ${SPACY_OUTPUT_DIR}\\n\\n\"\n",
        "\n",
        "printf \"\\n\\n**************************************** Starting training model...\\n\\n\"\n",
        "\n",
        "python -m spacy train $SPACY_BINS_DIR/acc_config.cfg \\\n",
        "--paths.train $SPACY_DATA_DIR/conll_train.spacy --paths.dev $SPACY_DATA_DIR/conll_valid.spacy \\\n",
        "--output $SPACY_OUTPUT_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e182595-49a0-4afc-b187-cffa09d426b9",
      "metadata": {
        "id": "7e182595-49a0-4afc-b187-cffa09d426b9"
      },
      "source": [
        "- `E`: Numéro de l’époque (epoch) en cours\n",
        "- `#`: Numéro du lot (batch) (par exemple: à l'étape initiale 0: 100 séquences ont été utilisées, cf [training.batcher.size] dans le fichier de config)\n",
        "- `LOSS TOK2VEC` : Perte associée à la représentation des tokens\n",
        "- `LOSS NER`: Perte associée à la prédiction des entités nommées\n",
        "- `ENTS_F`: Score F1 sur les entités (moyenne harmonique de la précision et du rappel)\n",
        "- `ENTS_P`: précision score (mesure la fraction des entités prédites par le modèle qui sont correctes)\n",
        "- `ENTS_R`: recall score (mesure la fraction des entités réelles qui sont correctement détectées par le modèle)\n",
        "- `SCORE`: score global du modèle, qui est généralement identique au score F1 (ENTS_F) pour la tâche de NER"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84dc1ffc-2429-4850-a906-9e715e4c40a7",
      "metadata": {
        "id": "84dc1ffc-2429-4850-a906-9e715e4c40a7"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde5aa58-1c77-48cf-9be6-336b8680608b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T10:00:26.364568Z",
          "iopub.status.busy": "2025-03-18T10:00:26.364432Z",
          "iopub.status.idle": "2025-03-18T10:03:36.009558Z",
          "shell.execute_reply": "2025-03-18T10:03:36.009101Z",
          "shell.execute_reply.started": "2025-03-18T10:00:26.364558Z"
        },
        "id": "bde5aa58-1c77-48cf-9be6-336b8680608b",
        "outputId": "2f0b3516-797d-4012-ed66-fa564fb42e05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start time: 2025-03-18 10:00:26\n",
            "\n",
            "\n",
            "***************************************** Training performances\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   92.28 \n",
            "NER R   91.84 \n",
            "NER F   92.06 \n",
            "SPEED   1769  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "ORG    91.53   86.28   88.83\n",
            "LOC    92.79   93.98   93.38\n",
            "MISC   86.04   87.46   86.74\n",
            "PER    94.94   95.87   95.40\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "/Users/mouslydiaw/Documents/ml-courses/nlp/ner_output/valid_evaluation.json\u001b[0m\n",
            "\n",
            "\n",
            "***************************************** Test performances\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   87.19 \n",
            "NER R   88.87 \n",
            "NER F   88.02 \n",
            "SPEED   1712  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "LOC    87.03   91.69   89.30\n",
            "PER    93.75   94.05   93.90\n",
            "ORG    86.16   84.29   85.22\n",
            "MISC   72.05   79.74   75.70\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "/Users/mouslydiaw/Documents/ml-courses/nlp/ner_output/test_evaluation.json\u001b[0m\n",
            "End time: 2025-03-18 10:01:29\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   97.27 \n",
            "NER R   97.31 \n",
            "NER F   97.29 \n",
            "SPEED   1778  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "ORG    97.10   96.25   96.67\n",
            "MISC   94.15   95.73   94.94\n",
            "PER    98.67   98.93   98.80\n",
            "LOC    97.36   97.29   97.32\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "/Users/mouslydiaw/Documents/ml-courses/nlp/ner_output/train_evaluation.json\u001b[0m\n",
            "\n",
            "\n",
            "***************************************** Validation performances\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   92.28 \n",
            "NER R   91.84 \n",
            "NER F   92.06 \n",
            "SPEED   1862  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "ORG    91.53   86.28   88.83\n",
            "LOC    92.79   93.98   93.38\n",
            "MISC   86.04   87.46   86.74\n",
            "PER    94.94   95.87   95.40\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "/Users/mouslydiaw/Documents/ml-courses/nlp/ner_output/valid_evaluation.json\u001b[0m\n",
            "\n",
            "\n",
            "***************************************** Test performances\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   87.19 \n",
            "NER R   88.87 \n",
            "NER F   88.02 \n",
            "SPEED   1748  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "LOC    87.03   91.69   89.30\n",
            "PER    93.75   94.05   93.90\n",
            "ORG    86.16   84.29   85.22\n",
            "MISC   72.05   79.74   75.70\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "/Users/mouslydiaw/Documents/ml-courses/nlp/ner_output/test_evaluation.json\u001b[0m\n",
            "End time: 2025-03-18 10:03:36\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "# performance evaluation\n",
        "START=$(date '+%Y-%m-%d %H:%M:%S')\n",
        "echo \"Start time: $START\"\n",
        "\n",
        "printf \"\\n\\n***************************************** Training performances\\n\"\n",
        "python -m spacy evaluate ${SPACY_OUTPUT_DIR}/model-best $SPACY_DATA_DIR/conll_train.spacy --output ${SPACY_OUTPUT_DIR}/train_evaluation.json\n",
        "\n",
        "printf \"\\n\\n***************************************** Validation performances\\n\"\n",
        "python -m spacy evaluate ${SPACY_OUTPUT_DIR}/model-best $SPACY_DATA_DIR/conll_valid.spacy --output ${SPACY_OUTPUT_DIR}/valid_evaluation.json\n",
        "\n",
        "printf \"\\n\\n***************************************** Test performances\\n\"\n",
        "python -m spacy evaluate ${SPACY_OUTPUT_DIR}/model-best $SPACY_DATA_DIR/conll_test.spacy --output ${SPACY_OUTPUT_DIR}/test_evaluation.json\n",
        "\n",
        "END=$(date '+%Y-%m-%d %H:%M:%S')\n",
        "echo \"End time: $END\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37f5e66a-2bc2-40c4-9622-29df9a2cd420",
      "metadata": {
        "id": "37f5e66a-2bc2-40c4-9622-29df9a2cd420"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "910d208b-ed62-4ecf-8c1c-0b529d678918",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T10:03:39.562837Z",
          "iopub.status.busy": "2025-03-18T10:03:39.562455Z",
          "iopub.status.idle": "2025-03-18T10:03:40.537864Z",
          "shell.execute_reply": "2025-03-18T10:03:40.537593Z",
          "shell.execute_reply.started": "2025-03-18T10:03:39.562813Z"
        },
        "id": "910d208b-ed62-4ecf-8c1c-0b529d678918",
        "outputId": "54018d1b-e3c1-4392-8f6d-d50895fd88fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Barack PER\n",
            "Obama PER\n",
            "London LOC\n"
          ]
        }
      ],
      "source": [
        "custom_nlp_ner = spacy.load(Path(environ[\"SPACY_OUTPUT_DIR\"], \"model-best\"))\n",
        "\n",
        "text_test = \"Barack Obama visited London in 2020.\"\n",
        "\n",
        "doc_test = custom_nlp_ner(text_test)\n",
        "for ent in doc_test.ents:\n",
        "    print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ca2f68d-b343-4c80-8c0e-f8304c06786d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-18T10:03:41.126780Z",
          "iopub.status.busy": "2025-03-18T10:03:41.126524Z"
        },
        "id": "3ca2f68d-b343-4c80-8c0e-f8304c06786d",
        "outputId": "e54cfb50-4ddc-40bf-ac76-05d73ea0b5b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/spacy/util.py:1835: UserWarning: [W124] 0.0.0.0:5000 is already in use, using the nearest available port 5001 as an alternative.\n",
            "  warnings.warn(Warnings.W124.format(host=host, port=start, serve_port=port))\n",
            "/opt/anaconda3/lib/python3.12/site-packages/spacy/displacy/__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
            "  warnings.warn(Warnings.W011)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Barack\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Obama\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " visited \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    London\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " in 2020.</div>\n",
              "</figure>\n",
              "</body>\n",
              "</html></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'ent' visualizer\n",
            "Serving on http://0.0.0.0:5001 ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spacy.displacy.serve(doc_test, style=\"ent\", auto_select_port=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6adc2c0-42a0-406b-9809-4d6cb4e2ba63",
      "metadata": {
        "id": "e6adc2c0-42a0-406b-9809-4d6cb4e2ba63"
      },
      "source": [
        "## Comment optimiser un modèle NER\n",
        "\n",
        "- **1. Optimiser les données**\n",
        "    - Qualité des annotations\n",
        "    - Volume de données\n",
        "    - Diversité\n",
        "- **Ajuster la configuration (config.cfg)**\n",
        "    - Taille du réseau (hidden_width) : par défaut 64 pour certains modèles. Tester 128 ou 256 pour un modèle plus puissant.\n",
        "    - Utilisation de vecteurs pré-entraînés : spécifier un vecteur comme en_core_web_lg ou des vecteurs custom\n",
        "    - Dropout : pour éviter le surapprentissage\n",
        "    - Augmenter max_steps ou max_epochs\n",
        "- **Stratégies d’entraînement**\n",
        "    - Évaluation fréquente: `eval_frequency = 200` permet de sauvegarder le meilleur modèle plus souvent.\n",
        "    - Batching intelligent utiliser un batching compounding\n",
        "- **4. Transfert de connaissance: utiliser un tok2vec pré-entraîné**\n",
        "- **6. Data augmentation (facultatif mais puissant)**\n",
        "     - Ajouter des variantes dans les textes : paraphrases, substitutions d’entités par d’autres, ajout de synonymes, ...\n",
        "     - Vous pouvez utiliser des outils comme `nlpaug`, `textattack`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f03190ed-ddb7-4aad-a8ff-d08401459a83",
      "metadata": {
        "id": "f03190ed-ddb7-4aad-a8ff-d08401459a83"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}